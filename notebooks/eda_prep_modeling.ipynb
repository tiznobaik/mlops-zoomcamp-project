{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/raw/Churn_Modelling_All.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['RowNumber', 'CustomerId', 'Surname']\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of numeric features\n",
    "numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "for feature in numeric_features:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df[feature], bins=50, kde=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of categorical features\n",
    "categorical_features = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember', 'Exited']\n",
    "for feature in categorical_features:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.countplot(x=feature, data=df)\n",
    "    plt.title(f'Count of {feature}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix (numeric columns only)\n",
    "plt.figure(figsize=(12, 6))\n",
    "numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'Exited']\n",
    "numeric_df = df[numeric_features]  # Select only numeric columns\n",
    "corr_matrix = numeric_df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print correlation with the target variable\n",
    "target = 'Exited'\n",
    "print(corr_matrix[target].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for selected features\n",
    "selected_features = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'Exited']\n",
    "sns.pairplot(df[selected_features], hue='Exited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Gender to binary (0 and 1)\n",
    "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 7500 records\n",
      "Validation set size: 1250 records\n",
      "Test set size: 1250 records\n",
      "Transformed training data shape: (7500, 11)\n",
      "        Age    Tenure   Balance  NumOfProducts  EstimatedSalary  HasCrCard  \\\n",
      "0  1.328762  1.028955  0.761715       0.803861         1.237787        0.0   \n",
      "1 -0.092881 -0.699103  0.234517      -0.914771         1.095526        0.0   \n",
      "2  1.423538  1.374567  0.337508      -0.914771         1.679687        1.0   \n",
      "3 -0.377209 -0.353492  0.225786      -0.914771        -1.378660        1.0   \n",
      "4  0.191448 -1.390327  0.119901      -0.914771         0.226947        0.0   \n",
      "\n",
      "   IsActiveMember  Gender  Geography_Germany  Geography_Spain  CreditScore  \n",
      "0             1.0     0.0                0.0              0.0          7.0  \n",
      "1             1.0     1.0                0.0              0.0          3.0  \n",
      "2             1.0     0.0                1.0              0.0          4.0  \n",
      "3             1.0     0.0                0.0              0.0          5.0  \n",
      "4             1.0     0.0                0.0              1.0          5.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['Exited'])\n",
    "y = df['Exited']\n",
    "\n",
    "# Split the data into train, validation, test, and production test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Verify the sizes\n",
    "print(f\"Training set size: {X_train.shape[0]} records\")\n",
    "print(f\"Validation set size: {X_valid.shape[0]} records\")\n",
    "print(f\"Test set size: {X_test.shape[0]} records\")\n",
    "\n",
    "# Identify numeric and binary columns\n",
    "numeric_features = ['Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "binary_features = ['HasCrCard', 'IsActiveMember', 'Gender']\n",
    "categorical_features = ['Geography']\n",
    "binning_features = ['CreditScore']\n",
    "\n",
    "# Create the preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('bin', 'passthrough', binary_features),  # Pass through binary features without change\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features),  # One-hot encode categorical features\n",
    "        ('credit_bin', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform'), binning_features)  # Binning for CreditScore\n",
    "    ], remainder='passthrough')  # Ensure passthrough for any remaining columns\n",
    "\n",
    "# Create the full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_preprocessed = pipeline.fit_transform(X_train)\n",
    "\n",
    "# Transform the validation and test data\n",
    "X_valid_preprocessed = pipeline.transform(X_valid)\n",
    "X_test_preprocessed = pipeline.transform(X_test)\n",
    "\n",
    "# Print the shape of the transformed training data\n",
    "print(f\"Transformed training data shape: {X_train_preprocessed.shape}\")\n",
    "\n",
    "# Generate feature names for all features including one-hot encoded features\n",
    "onehot_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features).tolist()\n",
    "preprocessor_feature_names = (\n",
    "    preprocessor.named_transformers_['num'].get_feature_names_out(numeric_features).tolist() +\n",
    "    binary_features +\n",
    "    onehot_feature_names +\n",
    "    binning_features  # Single binned CreditScore column\n",
    ")\n",
    "\n",
    "# Ensure the number of feature names matches the number of columns in the transformed data\n",
    "assert len(preprocessor_feature_names) == X_train_preprocessed.shape[1], \"Number of feature names does not match the number of columns in the transformed data.\"\n",
    "\n",
    "# Convert the preprocessed data back to DataFrame for better readability\n",
    "X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed, columns=preprocessor_feature_names)\n",
    "X_valid_preprocessed_df = pd.DataFrame(X_valid_preprocessed, columns=preprocessor_feature_names)\n",
    "X_test_preprocessed_df = pd.DataFrame(X_test_preprocessed, columns=preprocessor_feature_names)\n",
    "\n",
    "# Display the first few rows of the preprocessed training data\n",
    "print(X_train_preprocessed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the preprocessed data is already available\n",
    "# X_train_preprocessed_df, X_valid_preprocessed_df, X_test_preprocessed_df\n",
    "\n",
    "# Separate features and target\n",
    "y_train = y_train\n",
    "X_train = X_train_preprocessed_df\n",
    "\n",
    "y_valid = y_valid\n",
    "X_valid = X_valid_preprocessed_df\n",
    "\n",
    "y_test = y_test\n",
    "X_test = X_test_preprocessed_df\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "print(\"Validation Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, y_valid_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_valid, y_valid_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_valid, y_valid_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_valid, y_valid_pred):.4f}\")\n",
    "print(confusion_matrix(y_valid, y_valid_pred))\n",
    "print(classification_report(y_valid, y_valid_pred))\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found by GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Train final model with best parameters on the training set\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the validation set with the best model\n",
    "y_valid_pred_best = best_model.predict(X_valid)\n",
    "print(\"Validation Set Performance with Best Model:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, y_valid_pred_best):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_valid, y_valid_pred_best):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_valid, y_valid_pred_best):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_valid, y_valid_pred_best):.4f}\")\n",
    "print(confusion_matrix(y_valid, y_valid_pred_best))\n",
    "print(classification_report(y_valid, y_valid_pred_best))\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "print(\"Test Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix visualization\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Validation set performance\n",
    "plot_confusion_matrix(y_valid, y_valid_pred_best, 'Validation Set Confusion Matrix')\n",
    "\n",
    "# Test set performance\n",
    "plot_confusion_matrix(y_test, y_test_pred, 'Test Set Confusion Matrix')\n",
    "\n",
    "# Validation set ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_prob, title):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC Curve for validation set\n",
    "y_valid_pred_prob = best_model.predict_proba(X_valid)[:, 1]\n",
    "plot_roc_curve(y_valid, y_valid_pred_prob, 'Validation Set ROC Curve')\n",
    "\n",
    "# Plot ROC Curve for test set\n",
    "y_test_pred_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "plot_roc_curve(y_test, y_test_pred_prob, 'Test Set ROC Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to experiment with\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000)),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Support Vector Machine', SVC(probability=True))\n",
    "]\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "for name, model in models:\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, y_valid_pred)\n",
    "    precision = precision_score(y_valid, y_valid_pred)\n",
    "    recall = recall_score(y_valid, y_valid_pred)\n",
    "    f1 = f1_score(y_valid, y_valid_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': confusion_matrix(y_valid, y_valid_pred),\n",
    "        'classification_report': classification_report(y_valid, y_valid_pred)\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics['confusion_matrix'])\n",
    "    print(\"Classification Report:\")\n",
    "    print(metrics['classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Hyperparameter Tunning\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best parameters found by GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "y_valid_pred = best_rf.predict(X_valid)\n",
    "print(\"Validation Set Performance with Best Random Forest Model:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, y_valid_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_valid, y_valid_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_valid, y_valid_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_valid, y_valid_pred):.4f}\")\n",
    "print(confusion_matrix(y_valid, y_valid_pred))\n",
    "print(classification_report(y_valid, y_valid_pred))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "print(\"Test Set Performance with Best Random Forest Model:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best parameters found by GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "y_valid_pred = best_xgb.predict(X_valid)\n",
    "print(\"Validation Set Performance with Best XGBoost Model:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, y_valid_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_valid, y_valid_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_valid, y_valid_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_valid, y_valid_pred):.4f}\")\n",
    "print(confusion_matrix(y_valid, y_valid_pred))\n",
    "print(classification_report(y_valid, y_valid_pred))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_test_pred = best_xgb.predict(X_test)\n",
    "print(\"Test Set Performance with Best XGBoost Model:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
